<!DOCTYPE html>
<html lang="he" dir="rtl">
<head>
    <meta charset="UTF-8">
    <title>מצגת: אנטרופיית שאנון ותורת המידע</title>
    <style>
        /* CSS בסיסי להצגה ברורה, ניתן להתעלם לצורך העברה לגוגל סליידס */
        body { font-family: 'Arial', sans-serif; line-height: 1.6; margin: 20px; }
        .slide { border-bottom: 3px solid #0056b3; margin-bottom: 40px; padding-bottom: 20px; }
        .slide h2 { color: #0056b3; border-right: 5px solid #ffcc00; padding-right: 10px; }
        .lecturer-notes { background-color: #f0f0f0; border: 1px dashed #ccc; padding: 15px; margin-top: 15px; font-style: italic; }
        .formula { font-size: 1.2em; font-weight: bold; direction: ltr; }
    </style>
</head>
<body>

    <h1>מצגת: אנטרופיית שאנון - הבסיס לעולם הדיגיטלי</h1>

    <div class="slide" id="slide1">
        <h2>שקף 1: כותרת ופתיחה</h2>
        <h3>אנטרופיית שאנון: המדד המתמטי למידע 🧠</h3>
        <ul>
            <li>**תורת האינפורמציה** וקלוד שאנון (1948)</li>
            <li>השאלה: איך למדוד 'מידע' באופן מדויק ואוניברסלי?</li>
        </ul>
        <div class="lecturer-notes">
            **דברי המרצה:** "שלום לכולם. היום אנחנו צוללים לתוך אחד הרעיונות המכוננים ביותר של המאה ה-20: **אנטרופיית שאנון**. זהו הלב של **תורת האינפורמציה**. במקום לדבר על תוכן המסר ('מה נאמר'), שאנון שאל: 'כמה **אינפורמציה** המסר מכיל?'. הוא רצה ליצור מדד מתמטי, אובייקטיבי, שאינו תלוי בשפה, בתוכן או בחשיבות. זהו הבסיס לכל מה שאנחנו מכנים היום ה'עידן הדיגיטלי'."
        </div>
    </div>

    <div class="slide" id="slide2">
        <h2>שקף 2: המושג – אי-וודאות והפתעה</h2>
        <h3>האנטרופיה ($H$): מדד לאי-וודאות והפתעה ❓</h3>
        <ul>
            <li>**אי-וודאות:** $H$ מודדת את **מידת אי-הוודאות הממוצעת** בתוצאה של אירוע אקראי.</li>
            <li>**דוגמה:** מטבע הוגן = אנטרופיה גבוהה (מקסימום אי-וודאות).</li>
            <li>**דוגמה:** מטבע תמיד 'עץ' = אנטרופיה אפס (התוצאה ידועה).</li>
            <li>**הפתעה:** הקשר ההפוך: **אירוע נדיר** $\implies$ **אינפורמציה גבוהה** (מפתיע).</li>
        </ul>
        <div class="lecturer-notes">
            **דברי המרצה:** "האנטרופיה קשורה לשני מושגים: אי-וודאות והפתעה. אירוע ודאי, כמו זריחת השמש, מכיל אפס אינפורמציה מבחינה מתמטית. אירוע לא ודאי, כמו הטלת מטבע הוגן, הוא בעל אי-וודאות מקסימלית. ככל שהאירוע הוא פחות צפוי – כלומר, נדיר יותר – כך הוא נושא יותר 'הפתעה', ומבחינת שאנון, יותר אינפורמציה. האנטרופיה היא למעשה **הציפייה הממוצעת** לכמות ההפתעה שנכיל ממקור המידע."
        </div>
    </div>

    <div class="slide" id="slide3">
        <h2>שקף 3: יחידת המידה והנוסחה (הביט)</h2>
        <h3>$H$: המספר המינימלי של **ביטים** (Bits)</h3>
        <ul>
            <li>**מהו ביט?** יחידת המידה הבסיסית: תשובה ל**שאלת 'כן/לא'** או **'0/1'**.</li>
            <li>**האנטרופיה בביטים:** האנטרופיה היא ה**מספר הממוצע המינימלי של ביטים** שדרושים כדי לקודד מסר כלשהו.</li>
            <li>**הנוסחה (לצפייה בלבד):** <div class="formula">$H(X) = -\sum_{i} p(x_i) \log_2 p(x_i)$</div></li>
        </ul>
        <div class="lecturer-notes">
            **דברי המרצה:** "כל האינפורמציה בעולם הדיגיטלי בנויה על ביטים. הביט הוא יחידת המידה של האנטרופיה. השימוש בבסיס $log_2$ בנוסחה מבטיח שהמדד שלנו יהיה ב**ביטים**. אם למקור מידע יש אנטרופיה של 1.5 ביט, זה אומר שלא ניתן לקודד את המסרים שלו בפחות מ-1.5 ביטים בממוצע, בלי לאבד מידע. זו הגדרה יסודית שמקשרת בין הסתברות (Probability) לבין אחסון (Bits)."
        </div>
    </div>

    <div class="slide" id="slide4">
        <h2>שקף 4: יישום 1: תקשורת - גבולות הערוץ 📡</h2>
        <h3>קיבולת ערוץ: הגבול המוחלט למהירות השידור</h3>
        <ul>
            <li>**משפט שאנון-הארטלי:** האנטרופיה קובעת את **קיבולת הערוץ** ($C$) - המהירות המקסימלית שבה ניתן להעביר מידע בערוץ.</li>
            <li>**הגבול תלוי:** ברוחב הפס ($B$) וביחס אות-לרעש ($S/N$).</li>
            <li>**המשמעות:** אין טעם לנסות לשדר מהר יותר מהגבול התיאורטי הזה.</li>
        </ul>
        <div class="lecturer-notes">
            **דברי המרצה:** "בתחום התקשורת, שאנון לא רק מדד מידע, אלא קבע את גבולות היכולת שלנו להעביר אותו. זהו 'חוק מהירות האור' של עולם התקשורת. הגבול הזה תלוי רק ברוחב הפס של הערוץ וביחס בין עוצמת האות שאנו שולחים לבין עוצמת הרעש בסביבה. הנדסת תקשורת עוסקת בלהתקרב ככל האפשר לגבול שקבע שאנון."
        </div>
    </div>

    <div class="slide" id="slide5">
        <h2>שקף 5: תקשורת: יישום ב-WiFi וסלולר 📶</h2>
        <h3>שיפורים טכנולוגיים מול הגבול התיאורטי</h3>
        <ul>
            <li>**WiFi ו-5G:** המהירות שאנו חווים מתוכננת סביב הקיבולת התיאורטית של שאנון.</li>
            <li>**פרוטוקולים יעילים:** שדרוגים בטכנולוגיה (כמו WiFi 6 או 5G) הם מאמץ מתמיד **להתקרב** לגבול זה.</li>
            <li>**איך?** שיפור יחס אות-לרעש (S/N) וקידוד חכם יותר שמתגבר על רעש.</li>
        </ul>
        <div class="lecturer-notes">
            **דברי המרצה:** "כל שדרוג של ה-WiFi או מעבר לדור סלולרי חדש הוא ניסיון להשתמש בצורה חכמה יותר בגלי הרדיו הקיימים – **לדחוס** יותר אינפורמציה ליחידת זמן. שאנון נתן לנו את מפת הדרכים, ואנחנו הולכים בעקבותיה כדי למקסם את המהירות בשימוש יומיומי. האנטרופיה ($H$) משמשת כמהות המידע שאנחנו **מנסים** להעביר; קיבולת הערוץ ($C$) היא כמה **יכולים** להעביר."
        </div>
    </div>

    <div class="slide" id="slide6">
        <h2>שקף 6: יישום 2: מחשוב - הגבול של דחיסה 💾</h2>
        <h3>משפט קידוד המקור: האנטרופיה היא הגבול התחתון!</h3>
        <ul>
            <li>**הגדרת הגבול:** לא ניתן לדחוס קובץ (בצורה **חסרת-אובדן** - Lossless) לגודל קטן יותר מהאנטרופיה שלו.</li>
            <li>**המטרה:** הסרת **יתירות** (Redundancy) – מידע חוזר וצפוי.</li>
            <li>**דוגמה לדחיסה חסרת אובדן:** קובץ ZIP.</li>
        </ul>
        <div class="lecturer-notes">
            **דברי המרצה:** "אם בתקשורת האנטרופיה קובעת את מהירות השידור, במחשוב היא קובעת את **יעילות האחסון**. דחיסת נתונים היא שימוש יומיומי בתיאוריה של שאנון. **משפט קידוד המקור** קובע ש-H הוא גבול תחתון קשיח לגודל שאליו ניתן לדחוס את המידע. אלגוריתם דחיסה טוב מחפש את היתירות (הדפוסים החוזרים) ומסיר אותה, אך לעולם לא יוכל לרדת מתחת לגבול האנטרופיה."
        </div>
    </div>

    <div class="slide" id="slide7">
        <h2>שקף 7: דחיסת נתונים: JPEG, MP4 ו-MP3 🖼️</h2>
        <h3>היחס בין אנטרופיה לדחיסת אובדן</h3>
        <ul>
            <li>**דחיסת אובדן (Lossy):** (JPEG, MP4) אלגוריתמים אלו **מנצלים** מגבלות בתפיסה האנושית (ראייה/שמיעה).</li>
            <li>**הטריק:** משליכים מידע שהאדם לא יבחין בחסרונו, ובכך **מורידים את האנטרופיה** של מקור המידע.</li>
            <li>**דוגמאות:** טקסט דחיס מאוד (יתירות גבוהה). רעש לבן כמעט ולא דחיס (אנטרופיה מקסימלית).</li>
        </ul>
        <div class="lecturer-notes">
            **דברי המרצה:** "בדחיסת אובדן, אנחנו למעשה **משנים את מקור המידע** כדי שתהיה לו אנטרופיה נמוכה יותר, וכך מצליחים לדחוס מעבר לגבול ששאנון קבע למקור המקורי. האנטרופיה של שאנון היא הכלי שמשמש אותנו למדידת היעילות של כל סוגי הדחיסה. ככל שהמידע פחות אקראי, כך האנטרופיה שלו נמוכה יותר והוא ניתן לדחיסה יעילה יותר."
        </div>
    </div>

    <div class="slide" id="slide8">
        <h2>שקף 8: יישום 3: בינה מלאכותית - מדידת 'בלגן' 🤖</h2>
        <h3>אנטרופיה כמדד לאי-טוהר (Impurity) בנתונים</h3>
        <ul>
            <li>**מדד ל'טוהר':** האנטרופיה משמשת ב-AI כ**פונקציית עלות** (Cost Function) לאי-טוהר.</li>
            <li>**בלגן = אנטרופיה גבוהה:** קבוצת נתונים מעורבת (50% 'חתול', 50% 'כלב') = אי-וודאות מקסימלית.</li>
            <li>**סדר = אנטרופיה נמוכה:** קבוצת נתונים הומוגנית (100% 'חתול') = וודאות מקסימלית.</li>
            <li>**המטרה:** האלגוריתם שואף לבחור מהלכים שיפחיתו את האנטרופיה באופן מקסימלי.</li>
        </ul>
        <div class="lecturer-notes">
            **דברי המרצה:** "בתחום ה-AI, המונח אנטרופיה מקבל משמעות של 'בלגן' או 'אי-טוהר'. המטרה של מודל למידת מכונה היא תמיד להפחית את האנטרופיה, כלומר, להגיע למצב של 'טוהר' בנתונים – לקבוצות ממוינות. הפחתת האנטרופיה היא הדרך שבה מודלים כמו עצי החלטה לומדים ומקבלים החלטות."
        </div>
    </div>

    <div class="slide" id="slide9">
        <h2>שקף 9: דוגמה: אנטרופיה בבניית עץ החלטה 🌳</h2>
        <h3>רווח אינפורמציה (Information Gain)</h3>
        <ul>
            <li>**תהליך הלמידה:** בכל שלב בבניית העץ, האלגוריתם מחפש את הפיצול שיגרום ל**ירידה הגדולה ביותר באנטרופיה**.</li>
            <li>**המדד:** **רווח אינפורמציה** (Information Gain) הוא ההפרש בין האנטרופיה לפני הפיצול לבין האנטרופיה הממוצעת אחריו.</li>
            <li>**החשיבות:** המודל משתמש ב-IG כדי להבין **באיזו שאלה הכי כדאי לשאול** כדי להגיע להחלטה (למשל, האם 'יש פרווה' או 'האם צבעוני?').</li>
        </ul>
        <div class="lecturer-notes">
            **דברי המרצה:** "עץ החלטה הוא כמו משחק 'עשרים שאלות' מתוחכם. האלגוריתם מחשב את ה'בלגן' לפני הפיצול, ואז מחשב את ה'בלגן' אחרי הפיצול. ככל שרווח האינפורמציה גדול יותר, כך הפיצול שיצרנו 'מנקה' יותר בלגן (מפחית יותר אנטרופיה), ולכן זו ההחלטה הטובה ביותר. האנטרופיה של שאנון היא המנוע מאחורי קבלת ההחלטות האופטימלית במודלים רבים של AI."
        </div>
    </div>

</body>
</html>